{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7299270072992701,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014598540145985401,
      "grad_norm": 0.474153995513916,
      "learning_rate": 4.854368932038835e-06,
      "loss": 1.6011,
      "step": 10
    },
    {
      "epoch": 0.029197080291970802,
      "grad_norm": 0.47010478377342224,
      "learning_rate": 9.70873786407767e-06,
      "loss": 1.5736,
      "step": 20
    },
    {
      "epoch": 0.043795620437956206,
      "grad_norm": 0.521587073802948,
      "learning_rate": 1.4563106796116505e-05,
      "loss": 1.5892,
      "step": 30
    },
    {
      "epoch": 0.058394160583941604,
      "grad_norm": 0.689390242099762,
      "learning_rate": 1.8932038834951457e-05,
      "loss": 1.4888,
      "step": 40
    },
    {
      "epoch": 0.072992700729927,
      "grad_norm": 0.6157707571983337,
      "learning_rate": 2.3786407766990294e-05,
      "loss": 1.3035,
      "step": 50
    },
    {
      "epoch": 0.08759124087591241,
      "grad_norm": 0.6498854160308838,
      "learning_rate": 2.8640776699029125e-05,
      "loss": 1.1974,
      "step": 60
    },
    {
      "epoch": 0.10218978102189781,
      "grad_norm": 0.594110906124115,
      "learning_rate": 3.3495145631067966e-05,
      "loss": 0.984,
      "step": 70
    },
    {
      "epoch": 0.11678832116788321,
      "grad_norm": 0.692129909992218,
      "learning_rate": 3.83495145631068e-05,
      "loss": 0.9348,
      "step": 80
    },
    {
      "epoch": 0.13138686131386862,
      "grad_norm": 0.5947320461273193,
      "learning_rate": 4.3203883495145634e-05,
      "loss": 0.876,
      "step": 90
    },
    {
      "epoch": 0.145985401459854,
      "grad_norm": 0.558393120765686,
      "learning_rate": 4.805825242718447e-05,
      "loss": 0.8186,
      "step": 100
    },
    {
      "epoch": 0.16058394160583941,
      "grad_norm": 0.5756039023399353,
      "learning_rate": 5.29126213592233e-05,
      "loss": 0.7235,
      "step": 110
    },
    {
      "epoch": 0.17518248175182483,
      "grad_norm": 0.5095035433769226,
      "learning_rate": 5.7766990291262135e-05,
      "loss": 0.6742,
      "step": 120
    },
    {
      "epoch": 0.1897810218978102,
      "grad_norm": 0.6229369640350342,
      "learning_rate": 6.262135922330098e-05,
      "loss": 0.6809,
      "step": 130
    },
    {
      "epoch": 0.20437956204379562,
      "grad_norm": 0.6370835900306702,
      "learning_rate": 6.747572815533982e-05,
      "loss": 0.6938,
      "step": 140
    },
    {
      "epoch": 0.21897810218978103,
      "grad_norm": 0.5314831137657166,
      "learning_rate": 7.233009708737864e-05,
      "loss": 0.6704,
      "step": 150
    },
    {
      "epoch": 0.23357664233576642,
      "grad_norm": 0.6334070563316345,
      "learning_rate": 7.718446601941748e-05,
      "loss": 0.6334,
      "step": 160
    },
    {
      "epoch": 0.24817518248175183,
      "grad_norm": 0.6747769117355347,
      "learning_rate": 8.203883495145631e-05,
      "loss": 0.6424,
      "step": 170
    },
    {
      "epoch": 0.26277372262773724,
      "grad_norm": 0.6511096358299255,
      "learning_rate": 8.689320388349514e-05,
      "loss": 0.6378,
      "step": 180
    },
    {
      "epoch": 0.2773722627737226,
      "grad_norm": 0.8587298393249512,
      "learning_rate": 9.174757281553399e-05,
      "loss": 0.5863,
      "step": 190
    },
    {
      "epoch": 0.291970802919708,
      "grad_norm": 0.659281313419342,
      "learning_rate": 9.660194174757282e-05,
      "loss": 0.5792,
      "step": 200
    },
    {
      "epoch": 0.30656934306569344,
      "grad_norm": 0.9270609617233276,
      "learning_rate": 9.999935045760715e-05,
      "loss": 0.5764,
      "step": 210
    },
    {
      "epoch": 0.32116788321167883,
      "grad_norm": 0.7036126852035522,
      "learning_rate": 9.998780350676213e-05,
      "loss": 0.5707,
      "step": 220
    },
    {
      "epoch": 0.3357664233576642,
      "grad_norm": 0.79387366771698,
      "learning_rate": 9.996182611738734e-05,
      "loss": 0.6292,
      "step": 230
    },
    {
      "epoch": 0.35036496350364965,
      "grad_norm": 0.7426979541778564,
      "learning_rate": 9.992142578861446e-05,
      "loss": 0.5579,
      "step": 240
    },
    {
      "epoch": 0.36496350364963503,
      "grad_norm": 0.8333824276924133,
      "learning_rate": 9.986661418317759e-05,
      "loss": 0.5452,
      "step": 250
    },
    {
      "epoch": 0.3795620437956204,
      "grad_norm": 0.7631967067718506,
      "learning_rate": 9.97974071240465e-05,
      "loss": 0.5348,
      "step": 260
    },
    {
      "epoch": 0.39416058394160586,
      "grad_norm": 0.8771794438362122,
      "learning_rate": 9.971382458985882e-05,
      "loss": 0.5703,
      "step": 270
    },
    {
      "epoch": 0.40875912408759124,
      "grad_norm": 0.7312816381454468,
      "learning_rate": 9.961589070915268e-05,
      "loss": 0.5307,
      "step": 280
    },
    {
      "epoch": 0.4233576642335766,
      "grad_norm": 0.8898593187332153,
      "learning_rate": 9.95036337534012e-05,
      "loss": 0.5536,
      "step": 290
    },
    {
      "epoch": 0.43795620437956206,
      "grad_norm": 0.7912207841873169,
      "learning_rate": 9.937708612885126e-05,
      "loss": 0.5279,
      "step": 300
    },
    {
      "epoch": 0.45255474452554745,
      "grad_norm": 0.7731040716171265,
      "learning_rate": 9.923628436716836e-05,
      "loss": 0.4857,
      "step": 310
    },
    {
      "epoch": 0.46715328467153283,
      "grad_norm": 0.662590742111206,
      "learning_rate": 9.908126911489073e-05,
      "loss": 0.5064,
      "step": 320
    },
    {
      "epoch": 0.48175182481751827,
      "grad_norm": 0.6857175230979919,
      "learning_rate": 9.891208512169554e-05,
      "loss": 0.5207,
      "step": 330
    },
    {
      "epoch": 0.49635036496350365,
      "grad_norm": 0.8782424926757812,
      "learning_rate": 9.872878122748058e-05,
      "loss": 0.5195,
      "step": 340
    },
    {
      "epoch": 0.5109489051094891,
      "grad_norm": 0.8150352835655212,
      "learning_rate": 9.853141034826522e-05,
      "loss": 0.5425,
      "step": 350
    },
    {
      "epoch": 0.5255474452554745,
      "grad_norm": 0.8332362771034241,
      "learning_rate": 9.832002946091459e-05,
      "loss": 0.534,
      "step": 360
    },
    {
      "epoch": 0.5401459854014599,
      "grad_norm": 0.792351484298706,
      "learning_rate": 9.809469958669164e-05,
      "loss": 0.4862,
      "step": 370
    },
    {
      "epoch": 0.5547445255474452,
      "grad_norm": 0.9537925124168396,
      "learning_rate": 9.785548577364152e-05,
      "loss": 0.493,
      "step": 380
    },
    {
      "epoch": 0.5693430656934306,
      "grad_norm": 1.064953327178955,
      "learning_rate": 9.760245707781355e-05,
      "loss": 0.5066,
      "step": 390
    },
    {
      "epoch": 0.583941605839416,
      "grad_norm": 0.8237999081611633,
      "learning_rate": 9.733568654332618e-05,
      "loss": 0.4837,
      "step": 400
    },
    {
      "epoch": 0.5985401459854015,
      "grad_norm": 0.7828624248504639,
      "learning_rate": 9.705525118128073e-05,
      "loss": 0.4947,
      "step": 410
    },
    {
      "epoch": 0.6131386861313869,
      "grad_norm": 0.911079466342926,
      "learning_rate": 9.67612319475298e-05,
      "loss": 0.4785,
      "step": 420
    },
    {
      "epoch": 0.6277372262773723,
      "grad_norm": 0.7735104560852051,
      "learning_rate": 9.645371371930709e-05,
      "loss": 0.4984,
      "step": 430
    },
    {
      "epoch": 0.6423357664233577,
      "grad_norm": 0.8236644864082336,
      "learning_rate": 9.613278527072504e-05,
      "loss": 0.4813,
      "step": 440
    },
    {
      "epoch": 0.656934306569343,
      "grad_norm": 0.800072193145752,
      "learning_rate": 9.579853924714759e-05,
      "loss": 0.5068,
      "step": 450
    },
    {
      "epoch": 0.6715328467153284,
      "grad_norm": 0.8278487324714661,
      "learning_rate": 9.545107213844546e-05,
      "loss": 0.4626,
      "step": 460
    },
    {
      "epoch": 0.6861313868613139,
      "grad_norm": 0.8579379320144653,
      "learning_rate": 9.509048425114148e-05,
      "loss": 0.5015,
      "step": 470
    },
    {
      "epoch": 0.7007299270072993,
      "grad_norm": 0.9362450838088989,
      "learning_rate": 9.471687967945416e-05,
      "loss": 0.4784,
      "step": 480
    },
    {
      "epoch": 0.7153284671532847,
      "grad_norm": 0.9878629446029663,
      "learning_rate": 9.433036627524794e-05,
      "loss": 0.4683,
      "step": 490
    },
    {
      "epoch": 0.7299270072992701,
      "grad_norm": 0.8304235935211182,
      "learning_rate": 9.39310556168985e-05,
      "loss": 0.5026,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2055,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.883223642745078e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
